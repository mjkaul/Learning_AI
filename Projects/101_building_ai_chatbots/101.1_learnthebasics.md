# Learning AI 101.1: 

## Objective

- Understand what an LLM is, what it is made up of, and how it is trained.
- Objective #2
- More as needed

## Terms & concepts

- LLM: What does it stand for? What are the two basic files an LLM requires?
- Model inference
- Model training
- More as needed
- Transformer architecture - what is it? how does it work?


-----

# Module content

All these belong in a later course - too advanced for this stage. Use the coursera free AI for Everyone course instead.
1. Watch Andrej Karpathy's video ["Intro to Large Language Models"]](https://www.youtube.com/watch?v=zjkBMFhNj_g&t=1s). 
2. Watch Karpathy's video ["Let's build GPT: from scratch, in code, spelled out""](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=0s)
3. Watch Sebastian Raschka's video workshop ["Building LLMs from the Ground Up"](https://www.youtube.com/watch?v=quh7z1q7-uc).

## Subsections as needed

-----

# Assignment

- Write a short essay summarizing what an LLM is and how it is trained. How much does it cost and how long does it take to train an LLM based on 10TB of Internet text? 
	- The answer should include the the concepts of a parameter file and a run file; it takes roughly 6000 GPUs 12 days to train an LLM on 10TB of Internet text, and this would cost ~$2 million.
- Describe the different stages of tuning an LLM
	- Pre-training, fine-tuning
- More as needed

# Quiz

- What is the basic problem that an LLM neural network solves? 
	- Next-word prediction
- Why does Karpathy use the language of "dreams" to describe LLMs' output?
	- Because the LLM has been trained on all kinds of data, but it's a little inscrutable how it will use that inputted data to generate the corresponding output, and a lot of the output reflects "truthiness" but not necessarily truth. 
- Describe how to develop an AI assistant model
	- 